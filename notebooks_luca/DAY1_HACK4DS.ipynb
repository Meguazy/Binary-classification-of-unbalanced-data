{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO74qoGf+VcMgdRb3znn098",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meguazy/HACK_4DS/blob/main/notebooks_luca/DAY1_HACK4DS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Starting dataset"
      ],
      "metadata": {
        "id": "-Ha47nwWoTsz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qmD21Xwaismg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd30b59a-7f72-45bd-e5d6-ad71ae4cb348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HACK_4DS'...\n",
            "remote: Enumerating objects: 73, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 73 (delta 26), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (73/73), 11.56 MiB | 4.16 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Meguazy/HACK_4DS.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "id": "t3IsSBfmCDzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd HACK_4DS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_R2sqZ4kkX2",
        "outputId": "eec21f4d-bb9a-4b01-c04d-49f410f0aee9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HACK_4DS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "_iDiHJkQkVce"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = pd.read_csv(\"data/train_set.csv\", sep=\";\", quotechar=\"\\\"\", decimal=\",\")"
      ],
      "metadata": {
        "id": "FD8F2dIckg19"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = df_train.replace({\"external_score_ver03\": external_score_ver03_dictionary})"
      ],
      "metadata": {
        "id": "W-TVJWB_0OV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train[[\"application_ID\", \"decision_date\", \"province\", \"juridical_form\", \"industry_sector\", \"region\", \"geo_area\"]] = df_train[[\"application_ID\", \"decision_date\", \"province\", \"juridical_form\", \"industry_sector\", \"region\", \"geo_area\"]].astype(str)"
      ],
      "metadata": {
        "id": "PwzwzBqWtxKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_columns = [\"application_ID\", \"company_ID\",\n",
        "                \"cr_available\", \"province\", \"core_income_ratio\", \"geo_area\", \"region\", \"juridical_form\", \"industry_sector\",\n",
        "                \"std_tension_a_revoca_autoliquidanti\", \"avg_tension_a_revoca_autoliquidanti\", \"last_tension_a_revoca_autoliquidanti\",\n",
        "                \"last_rel_used_a_revoca_autoliquidanti\", \"avg_rel_used_a_revoca_autoliquidanti\", \"max_rel_used_a_revoca_autoliquidanti\",\n",
        "                \"avg_rel_used_a_scadenza\", \"last_rel_used_a_scadenza\", \"max_rel_used_a_scadenza\",\n",
        "                \"avg_count_enti_affidanti\", \"last_count_enti_affidanti\" , \"max_count_enti_affidanti\",\n",
        "                \"std_count_numero_prima_info\", \"last_count_numero_prima_info\", \"avg_count_numero_prima_info\",\n",
        "                \"days_to_deafult\", \"cr_available\"]"
      ],
      "metadata": {
        "id": "Ok8ZGlQrvkeA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA on Dropped dataset"
      ],
      "metadata": {
        "id": "i1DExUzECNly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHTpD5nQLGP3",
        "outputId": "eeaa1f79-f926-4011-a7cf-54c3207b8466"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped = pd.read_csv(\"data/dropped.csv\")"
      ],
      "metadata": {
        "id": "z5i3XCqGATMS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import lightgbm as lgb\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "metadata": {
        "id": "dTOTYrsgClid"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_columns = ['external_score_ver01',\n",
        "       'external_score_ver02', 'late_payment_score',\n",
        "       'external_score_late_payment_integrated', 'external_score_moderate',\n",
        "       'external_score_adverse', 'external_score_ver03', 'age',\n",
        "       'gross_margin_ratio', 'cash_asset_ratio',\n",
        "       'consolidated_liabilities_ratio', 'tangible_assets_ratio', 'revenues',\n",
        "       'last_statement_age', 'overrun_freq_a_revoca_autoliquidanti',\n",
        "       'max_tension_a_revoca_autoliquidanti',\n",
        "       'std_rel_used_a_revoca_autoliquidanti', 'overrun_freq_a_scadenza',\n",
        "       'std_rel_used_a_scadenza', 'std_count_enti_affidanti',\n",
        "       'max_count_numero_prima_info', 'decision_month']"
      ],
      "metadata": {
        "id": "3tRZWdRgDKR-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mapper = DataFrameMapper([(pca_columns, StandardScaler())])\n",
        "# scaled_features = mapper.fit_transform(df_dropped[pca_columns].copy(), len(pca_columns))\n",
        "# concatDatasetScaled = pd.DataFrame(scaled_features, index=df_dropped[pca_columns].index, columns=pca_columns)"
      ],
      "metadata": {
        "id": "momtmDkKEy99"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # to avoid overfitting\n",
        "# pca = PCA(n_components = 13)\n",
        "\n",
        "# pca_array = pca.fit_transform(concatDatasetScaled)\n",
        "\n",
        "# df_pca = pd.DataFrame(pca_array)\n",
        "\n",
        "# df_dropped[['principal_component_1', 'principal_component_2']] = pca.fit_transform(concatDatasetScaled)"
      ],
      "metadata": {
        "id": "6DM9Qt89C3_g"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_pca_concat = pd.concat([df_pca, df_dropped.target], axis = 1)"
      ],
      "metadata": {
        "id": "jvyFlGKJH2oP"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(df_pca_concat.iloc[:,0:13], df_pca_concat.target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "AUj1bxmgIqBY"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGBM with PCA (scaled)"
      ],
      "metadata": {
        "id": "yezqmg6EX610"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Applying undersampling\n",
        "# undersampler = RandomUnderSampler(random_state=42)\n",
        "# X_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "oY4OU8lgL56n"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Creating a LightGBM dataset\n",
        "# train_data = lgb.Dataset(X_resampled, label=y_resampled)"
      ],
      "metadata": {
        "id": "EIHnMg9GMJgZ"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Setting up parameters for LightGBM\n",
        "# params = {\n",
        "#     'objective': 'binary',\n",
        "#     'metric': 'binary_error'  # You can change the metric as per your requirement\n",
        "# }"
      ],
      "metadata": {
        "id": "6Olqz9bWMNGH"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Training the model\n",
        "# num_round = 50\n",
        "# bst = lgb.train(params, train_data, num_round)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf49IKfRMUcQ",
        "outputId": "465c332e-7dd1-4768-99d5-147db1eca246"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 5545, number of negative: 5545\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001494 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3315\n",
            "[LightGBM] [Info] Number of data points in the train set: 11090, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Making predictions\n",
        "# y_pred_lgbm = bst.predict(X_test, num_iteration=bst.best_iteration)"
      ],
      "metadata": {
        "id": "fCO4iTEDMU_M"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Converting probabilities to binary predictions\n",
        "# y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred_lgbm]"
      ],
      "metadata": {
        "id": "OjA_MU9HMWhB"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Accuracy: \", accuracy_score(y_test, y_pred_binary))\n",
        "# print(\"F1 score:\", f1_score(y_test, y_pred_binary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ywypuLvMX1t",
        "outputId": "8b680e40-cb9c-41b6-c0c8-c8e163f920de"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.6569377243639769\n",
            "F1 score: 0.444949494949495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# cm = confusion_matrix(y_test, y_pred_binary)\n",
        "\n",
        "# TN, FP, FN, TP = confusion_matrix(y_test, y_pred_binary).ravel()\n",
        "\n",
        "# print('True Positive(TP)  = ', TP)\n",
        "# print('False Positive(FP) = ', FP)\n",
        "# print('True Negative(TN)  = ', TN)\n",
        "# print('False Negative(FN) = ', FN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZuxlwWeNPPq",
        "outputId": "91bfbe78-d691-4683-d3e6-3a8c1b9c5b49"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Positive(TP)  =  886\n",
            "False Positive(FP) =  1769\n",
            "True Negative(TN)  =  3289\n",
            "False Negative(FN) =  463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGBM ..."
      ],
      "metadata": {
        "id": "Ez8A5M01SGdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_dropped[train_columns], df_dropped.target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Qf9u4IFC3nNL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ... with StandardScaled features ..."
      ],
      "metadata": {
        "id": "MyN8VBzD47Iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "8o2ru7Wi1kVY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ... and Undersampling (no PCA)"
      ],
      "metadata": {
        "id": "vTmk6cQUAJqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying undersampling\n",
        "sampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
        "# sampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = sampler.fit_resample(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "sPuhqbYI5Du3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your LightGBM classifier\n",
        "lgb_model = lgb.LGBMClassifier()\n",
        "\n",
        "param_grid = {\n",
        "  'task' : ['predict'],\n",
        "  'boosting': ['gbdt' ],\n",
        "  'objective': ['binary'],\n",
        "  'num_iterations': [  2000, 3100, 5000  ],\n",
        "  'learning_rate':[  0.05, 0.005 ],\n",
        "  'num_leaves':[ 7, 15, 31  ],\n",
        "  'max_depth' :[ 10,15,25],\n",
        "  'min_data_in_leaf':[15,25 ],\n",
        "  'feature_fraction': [ 0.6, 0.8,  0.9],\n",
        "  'bagging_fraction': [  0.6, 0.8 ],\n",
        "  'bagging_freq': [100, 200, 400],\n",
        "  'verbose':[0],\n",
        "  'metric': ['binary_error'],\n",
        "  'random_state':[42]\n",
        "}\n",
        "\n",
        "# Create GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=lgb_model, param_grid=param_grid, cv=5, scoring='f1', n_jobs=6, verbose=10)\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Parameters: \", best_params)\n",
        "print(\"Best F1: \", grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "xg-X_xFc7tLL",
        "outputId": "e73e0bfb-a8b8-4195-f6d2-6b0a71fde33e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1944 candidates, totalling 9720 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-579840c41b84>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Get the best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1705\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1706\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model with best parameters on the test set\n",
        "best_lgb_classifier = lgb.LGBMClassifier(**best_params)\n",
        "best_lgb_classifier.fit(X_train, y_train)\n",
        "y_pred = best_lgb_classifier.predict(X_test)\n",
        "\n",
        "y_pred = best_lgb_classifier.predict(X_test_scaled)\n",
        "\n",
        "# Converting probabilities to binary predictions\n",
        "y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred_binary))\n",
        "print(\"F1 score: \", f1_score(y_test, y_pred_binary))"
      ],
      "metadata": {
        "id": "L6lK6pXI7_4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W7lqAeB5XvwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a LightGBM dataset\n",
        "train_data = lgb.Dataset(X_resampled, label=y_resampled)\n",
        "\n",
        "# Setting up parameters for LightGBM\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_error',\n",
        "    'learning_rate': 0.05,\n",
        "    'random_state': 42,\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "# Training the model\n",
        "num_round = 3100\n",
        "bst = lgb.train(params, train_data, num_round)"
      ],
      "metadata": {
        "id": "Nc6Q9KNhHYfz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions\n",
        "y_pred = bst.predict(X_test_scaled, num_iteration=bst.best_iteration)\n",
        "\n",
        "# Converting probabilities to binary predictions\n",
        "y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred_binary))\n",
        "print(\"F1 score: \", f1_score(y_test, y_pred_binary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZvyAmeWIguh",
        "outputId": "8ab41dee-e398-4a82-951b-a9e5441a295b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7089121273606992\n",
            "F1 score:  0.5108838185156046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test and Submission"
      ],
      "metadata": {
        "id": "3tLhGvfN2hhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"data/test_set.csv\", sep=\";\", quotechar=\"\\\"\", decimal=\",\")"
      ],
      "metadata": {
        "id": "rqCRCcm2kwbj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['decision_date'] = pd.to_datetime(df_test['decision_date'])\n",
        "\n",
        "df_test['decision_month'] = df_test['decision_date'].dt.month"
      ],
      "metadata": {
        "id": "zaExOKvJqUpL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test[['late_payment_score', 'external_score_late_payment_integrated', 'external_score_moderate', 'external_score_adverse', 'external_score_ver03']] = df_test[['late_payment_score', 'external_score_late_payment_integrated', 'external_score_moderate', 'external_score_adverse', 'external_score_ver03']].fillna(df_test[['late_payment_score', 'external_score_late_payment_integrated', 'external_score_moderate', 'external_score_adverse', 'external_score_ver03']].median())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1BhwAzXqii3",
        "outputId": "eaf13212-e6bf-4432-8aa0-3018f19c43ed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-70f4a741621b>:1: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df_test[['late_payment_score', 'external_score_late_payment_integrated', 'external_score_moderate', 'external_score_adverse', 'external_score_ver03']] = df_test[['late_payment_score', 'external_score_late_payment_integrated', 'external_score_moderate', 'external_score_adverse', 'external_score_ver03']].fillna(df_test[['late_payment_score', 'external_score_late_payment_integrated', 'external_score_moderate', 'external_score_adverse', 'external_score_ver03']].median())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "external_score_ver03_dictionary = {\n",
        "    \"MISSING\":None,\n",
        "    \"A\":14,\n",
        "    \"B\":13,\n",
        "    \"C\":12,\n",
        "    \"D\":11,\n",
        "    \"E\":10,\n",
        "    \"F\":9,\n",
        "    \"G\":8,\n",
        "    \"H\":7,\n",
        "    \"I\":6,\n",
        "    \"L\":5,\n",
        "    \"M\":4,\n",
        "    \"N\":3,\n",
        "    \"O\":2,\n",
        "    \"P\":1\n",
        "}"
      ],
      "metadata": {
        "id": "W2e1g8XQrNOA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df_test.replace({\"external_score_ver03\": external_score_ver03_dictionary})"
      ],
      "metadata": {
        "id": "r9bRIB3Mrilx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test[train_columns] = scaler.transform(df_test[train_columns])"
      ],
      "metadata": {
        "id": "S-CE4wzsNTsa"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions\n",
        "y_test_pred = bst.predict(df_test[train_columns], num_iteration=bst.best_iteration)\n",
        "\n",
        "# Converting probabilities to binary predictions\n",
        "y_test_pred_binary = [1 if pred > 0.5 else 0 for pred in y_test_pred]"
      ],
      "metadata": {
        "id": "oPUXkQD9Vmub"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame(y_test_pred_binary, columns=[\"label\"])"
      ],
      "metadata": {
        "id": "e2Iz0L2Yrv8r"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv(\"file.csv\", index=False)"
      ],
      "metadata": {
        "id": "RE2SBQXzr9uh"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}