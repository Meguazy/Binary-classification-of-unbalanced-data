{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meguazy/HACK_4DS/blob/main/notebooks_fra/HACK4DS_Day1_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qmD21Xwaismg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d1af76c-d88c-4829-efaa-6eb0b9b771a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HACK_4DS'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Counting objects: 100% (106/106), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 106 (delta 44), reused 4 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (106/106), 11.92 MiB | 4.68 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Meguazy/HACK_4DS.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3IsSBfmCDzn",
        "outputId": "9cf3138d-132d-464c-8c7b-64248cb3bf29"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/HACK_4DS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_R2sqZ4kkX2",
        "outputId": "68bb1146-f812-4282-c6e8-ceffad1bbbcb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HACK_4DS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial"
      ],
      "metadata": {
        "id": "-Ha47nwWoTsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHTpD5nQLGP3",
        "outputId": "e8ab8d84-fee8-4d5f-e052-ec091fdd31df"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "import lightgbm as lgb\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "_iDiHJkQkVce"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"data2/test_set.csv\", sep=\";\", quotechar=\"\\\"\", decimal=\",\")"
      ],
      "metadata": {
        "id": "rqCRCcm2kwbj"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"data2/train_set.csv\", sep=\";\", quotechar=\"\\\"\", decimal=\",\")"
      ],
      "metadata": {
        "id": "FD8F2dIckg19"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "tgyeiRX7epi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "external_score_ver03_dictionary = {\n",
        "    \"MISSING\":None,\n",
        "    \"A\":14,\n",
        "    \"B\":13,\n",
        "    \"C\":12,\n",
        "    \"D\":11,\n",
        "    \"E\":10,\n",
        "    \"F\":9,\n",
        "    \"G\":8,\n",
        "    \"H\":7,\n",
        "    \"I\":6,\n",
        "    \"L\":5,\n",
        "    \"M\":4,\n",
        "    \"N\":3,\n",
        "    \"O\":2,\n",
        "    \"P\":1\n",
        "}\n",
        "\n",
        "df_train = df_train.replace({\"external_score_ver03\": external_score_ver03_dictionary})\n",
        "df_test = df_test.replace({\"external_score_ver03\": external_score_ver03_dictionary})"
      ],
      "metadata": {
        "id": "NMttmmMtUojp"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate df_train and df_test\n",
        "df_combined = pd.concat([df_train, df_test], axis=0)\n",
        "\n",
        "# List of columns to encode\n",
        "columns_to_encode = ['province', 'juridical_form', 'industry_sector', 'region', 'geo_area', 'decision_date']\n",
        "\n",
        "# Instantiate LabelEncoder\n",
        "label_encoders = {}\n",
        "\n",
        "# Encode each column iteratively\n",
        "for column in columns_to_encode:\n",
        "    # Instantiate LabelEncoder for the current column\n",
        "    label_encoders[column] = LabelEncoder()\n",
        "\n",
        "    # Fit label encoder on combined data\n",
        "    label_encoders[column].fit(df_combined[column])\n",
        "\n",
        "    # Transform both training and testing data\n",
        "    df_train[column] = label_encoders[column].transform(df_train[column])\n",
        "    df_test[column] = label_encoders[column].transform(df_test[column])"
      ],
      "metadata": {
        "id": "_NkmKUtUYcWR"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_columns = ['decision_date', 'company_ID', 'external_score_ver01',\n",
        "       'external_score_ver02', 'late_payment_score',\n",
        "       'external_score_late_payment_integrated', 'external_score_moderate',\n",
        "       'external_score_adverse', 'external_score_ver03', 'age', 'province',\n",
        "       'juridical_form', 'industry_sector', 'gross_margin_ratio',\n",
        "       'core_income_ratio', 'cash_asset_ratio',\n",
        "       'consolidated_liabilities_ratio', 'tangible_assets_ratio', 'revenues',\n",
        "       'cr_available', 'region', 'geo_area', 'last_statement_age',\n",
        "       'overrun_freq_a_revoca_autoliquidanti',\n",
        "       'avg_tension_a_revoca_autoliquidanti',\n",
        "       'std_tension_a_revoca_autoliquidanti',\n",
        "       'max_tension_a_revoca_autoliquidanti',\n",
        "       'last_tension_a_revoca_autoliquidanti',\n",
        "       'avg_rel_used_a_revoca_autoliquidanti',\n",
        "       'std_rel_used_a_revoca_autoliquidanti',\n",
        "       'max_rel_used_a_revoca_autoliquidanti',\n",
        "       'last_rel_used_a_revoca_autoliquidanti', 'overrun_freq_a_scadenza',\n",
        "       'avg_rel_used_a_scadenza', 'std_rel_used_a_scadenza',\n",
        "       'max_rel_used_a_scadenza', 'last_rel_used_a_scadenza',\n",
        "       'avg_count_enti_affidanti', 'std_count_enti_affidanti',\n",
        "       'max_count_enti_affidanti', 'last_count_enti_affidanti',\n",
        "       'avg_count_numero_prima_info', 'std_count_numero_prima_info',\n",
        "       'max_count_numero_prima_info', 'last_count_numero_prima_info']\n",
        "\n",
        "reg_columns = ['decision_date', 'company_ID', 'external_score_ver01',\n",
        "       'external_score_ver02', 'external_score_ver03', 'age', 'province',\n",
        "       'juridical_form', 'industry_sector', 'gross_margin_ratio',\n",
        "       'core_income_ratio', 'cash_asset_ratio',\n",
        "       'consolidated_liabilities_ratio', 'tangible_assets_ratio', 'revenues',\n",
        "       'cr_available', 'region', 'geo_area', 'last_statement_age',\n",
        "       'overrun_freq_a_revoca_autoliquidanti',\n",
        "       'avg_tension_a_revoca_autoliquidanti',\n",
        "       'std_tension_a_revoca_autoliquidanti',\n",
        "       'max_tension_a_revoca_autoliquidanti',\n",
        "       'last_tension_a_revoca_autoliquidanti',\n",
        "       'avg_rel_used_a_revoca_autoliquidanti',\n",
        "       'std_rel_used_a_revoca_autoliquidanti',\n",
        "       'max_rel_used_a_revoca_autoliquidanti',\n",
        "       'last_rel_used_a_revoca_autoliquidanti', 'overrun_freq_a_scadenza',\n",
        "       'avg_rel_used_a_scadenza', 'std_rel_used_a_scadenza',\n",
        "       'max_rel_used_a_scadenza', 'last_rel_used_a_scadenza',\n",
        "       'avg_count_enti_affidanti', 'std_count_enti_affidanti',\n",
        "       'max_count_enti_affidanti', 'last_count_enti_affidanti',\n",
        "       'avg_count_numero_prima_info', 'std_count_numero_prima_info',\n",
        "       'max_count_numero_prima_info', 'last_count_numero_prima_info']"
      ],
      "metadata": {
        "id": "rmHlg-SQRbsi"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Classificator"
      ],
      "metadata": {
        "id": "CRybM-5OMZUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(df_train[class_columns], df_train.target, test_size=0.15, random_state=42)\n",
        "\n",
        "train_data = lgb.Dataset(X_train_class, label=y_train_class)\n",
        "\n",
        "# Setting up parameters for LightGBM\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_error',\n",
        "    'learning_rate': 0.05,\n",
        "    'random_state': 42,\n",
        "    'num_iterations': 5000,\n",
        "    'is_unbalance': True,\n",
        "    'max_bin': 10,\n",
        "    'num_leaves': 50,\n",
        "    'n_estimators': 200,\n",
        "    'verbose': -1\n",
        "}\n",
        "\n",
        "# Training the model\n",
        "bst = lgb.train(params, train_data)\n",
        "\n",
        "# Making predictions\n",
        "y_pred_class = bst.predict(X_test_class, num_iteration=5000)\n",
        "\n",
        "# Converting probabilities to binary predictions\n",
        "y_pred_binary = [1 if pred > 0.4132 else 0 for pred in y_pred_class]\n",
        "\n",
        "# Calculating F1 score\n",
        "f1 = f1_score(y_test_class, y_pred_binary)\n",
        "print(\"F1 score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XczGqIAlMpgA",
        "outputId": "0ccd8ed3-24b9-4491-a7ec-8b48ac0c7b2f"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.6055149127743388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Submission"
      ],
      "metadata": {
        "id": "8CHiCw8YwN4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions\n",
        "submission_class = bst.predict(df_test[class_columns], num_iteration=5000)\n",
        "\n",
        "# Converting probabilities to binary predictions\n",
        "submission_class_binary = [1 if pred > 0.4132 else 0 for pred in submission_class]\n",
        "\n",
        "submission = pd.DataFrame(submission_class_binary, columns=[\"label\"])\n",
        "\n",
        "submission.to_csv(\"file.csv\", index=False)"
      ],
      "metadata": {
        "id": "EdqVbXKcwRAV"
      },
      "execution_count": 190,
      "outputs": []
    }
  ]
}