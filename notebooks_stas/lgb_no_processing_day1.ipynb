{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meguazy/HACK_4DS/blob/main/notebooks_stas/lgb_no_processing_day1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qmD21Xwaismg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc373066-047a-4be3-da3b-6b65e92065be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HACK_4DS'...\n",
            "remote: Enumerating objects: 77, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 77 (delta 28), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (77/77), 11.56 MiB | 3.95 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Meguazy/HACK_4DS.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3IsSBfmCDzn",
        "outputId": "78c03fe0-c5e5-4edd-b54e-6b5edafd0108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/HACK_4DS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_R2sqZ4kkX2",
        "outputId": "2625fe94-b3bf-480d-9642-80d9e6579539"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HACK_4DS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial"
      ],
      "metadata": {
        "id": "-Ha47nwWoTsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHTpD5nQLGP3",
        "outputId": "0326a5f9-d98d-4001-d323-7027f3e7dbb5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "import lightgbm as lgb\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "_iDiHJkQkVce"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"data/test_set.csv\", sep=\";\", quotechar=\"\\\"\", decimal=\",\")"
      ],
      "metadata": {
        "id": "rqCRCcm2kwbj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"data/train_set.csv\", sep=\";\", quotechar=\"\\\"\", decimal=\",\")"
      ],
      "metadata": {
        "id": "FD8F2dIckg19"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "tgyeiRX7epi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "external_score_ver03_dictionary = {\n",
        "    \"MISSING\":None,\n",
        "    \"A\":14,\n",
        "    \"B\":13,\n",
        "    \"C\":12,\n",
        "    \"D\":11,\n",
        "    \"E\":10,\n",
        "    \"F\":9,\n",
        "    \"G\":8,\n",
        "    \"H\":7,\n",
        "    \"I\":6,\n",
        "    \"L\":5,\n",
        "    \"M\":4,\n",
        "    \"N\":3,\n",
        "    \"O\":2,\n",
        "    \"P\":1\n",
        "}\n",
        "\n",
        "df_train = df_train.replace({\"external_score_ver03\": external_score_ver03_dictionary})\n",
        "df_test = df_test.replace({\"external_score_ver03\": external_score_ver03_dictionary})"
      ],
      "metadata": {
        "id": "NMttmmMtUojp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate df_train and df_test\n",
        "df_combined = pd.concat([df_train, df_test], axis=0)\n",
        "\n",
        "# List of columns to encode\n",
        "columns_to_encode = ['province', 'juridical_form', 'industry_sector', 'region', 'geo_area', 'decision_date']\n",
        "\n",
        "# Instantiate LabelEncoder\n",
        "label_encoders = {}\n",
        "\n",
        "# Encode each column iteratively\n",
        "for column in columns_to_encode:\n",
        "    # Instantiate LabelEncoder for the current column\n",
        "    label_encoders[column] = LabelEncoder()\n",
        "\n",
        "    # Fit label encoder on combined data\n",
        "    label_encoders[column].fit(df_combined[column])\n",
        "\n",
        "    # Transform both training and testing data\n",
        "    df_train[column] = label_encoders[column].transform(df_train[column])\n",
        "    df_test[column] = label_encoders[column].transform(df_test[column])"
      ],
      "metadata": {
        "id": "_NkmKUtUYcWR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['application_ID', 'days_to_default']\n",
        "\n",
        "# Drop the columns from the DataFrame\n",
        "df_train = df_train.drop(columns=columns_to_drop)\n",
        "df_train_no_target = df_train.drop(columns=['target'])\n",
        "\n",
        "df_test = df_test.drop(columns=['application_ID'])"
      ],
      "metadata": {
        "id": "ftdEJsT2VQYe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LGB"
      ],
      "metadata": {
        "id": "Ez8A5M01SGdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_train_no_target, df_train.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Applying undersampling\n",
        "undersampler = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# Creating a LightGBM dataset\n",
        "train_data = lgb.Dataset(X_resampled, label=y_resampled)\n",
        "\n",
        "# Setting up parameters for LightGBM\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_error',\n",
        "    'learning_rate': 0.05,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Training the model\n",
        "num_round = 3100\n",
        "bst = lgb.train(params, train_data, num_round)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
        "\n",
        "# Converting probabilities to binary predictions\n",
        "y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
        "\n",
        "# Calculating F1 score\n",
        "f1 = f1_score(y_test, y_pred_binary)\n",
        "print(\"F1 score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXzGiwn0S-bG",
        "outputId": "25928df8-1198-44da-da31-7584366b3658"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 20080, number of negative: 20080\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128861 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6190\n",
            "[LightGBM] [Info] Number of data points in the train set: 40160, number of used features: 45\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "F1 score: 0.5977701543739281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submit solution"
      ],
      "metadata": {
        "id": "DEA6Y5Wz3IkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions\n",
        "y_test_pred = bst.predict(df_test, num_iteration=bst.best_iteration)\n",
        "\n",
        "# Converting probabilities to binary predictions\n",
        "y_test_pred_binary = [1 if pred > 0.5 else 0 for pred in y_test_pred]"
      ],
      "metadata": {
        "id": "oPUXkQD9Vmub"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame(y_test_pred_binary, columns=[\"label\"])"
      ],
      "metadata": {
        "id": "e2Iz0L2Yrv8r"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv(\"file.csv\", index=False)"
      ],
      "metadata": {
        "id": "RE2SBQXzr9uh"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}